## lobe-chat
```bash
docker run -d -p 3210:3210 \
  -e ACCESS_CODE=liukang960215 \
  -e PROXY_URL=http://172.30.XXX.XXX:7892 \  
  --restart always \
  --name lobe-chat \
  lobehub/lobe-chat
```
### docker-compose 启动
```yml
services:
  lobechat:
    image: lobehub/lobe-chat
    ports:
      - "3210:3210"
    environment:
      - ACCESS_CODE=liukang96021
      - PROXY_URL=http://172.30.XXX.XXX:7892
    restart: always
    networks:
      - lobechatnet

networks:
  lobechatnet:
    name: lobechatnet
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 192.188.45.0/24
          gateway: 192.188.45.1
```




# elasticsearch docker 启动

可以使用两种方式：
首先创建一个网络，用于 es 后续与其他服务通信
```bash
docker network create --driver bridge --subnet 192.168.50.0/24 --gateway 192.168.50.1 esnet
```

1. bind mount 方式，将配置文件、数据文件、日志文件都挂载到宿主机上（需要手动复制配置文件，手动管理文件夹权限）
```bash
# 临时启动一个 es 
docker run -d --rm --name temp-es -p 9200:9200 -p 9300:9300 -e "discovery.type=single-node" elasticsearch:7.17.27
# 进入容器内部
docker exec -it temp-es bash
cat /etc/passwd # 查看用户
# 查看运行的 UID 与 GID 
id  # 启动时的用户
# id ： uid=0(root) gid=0(root) groups=0(root)uid=0(root) gid=0(root) groups=0(root)
id 用户名  # 查看用户名对应的 UID 与 GID
# id elasticsearch  # uid=1000(elasticsearch) gid=1000(elasticsearch) groups=1000(elasticsearch),0(root)


# 另一个终端窗口，复制配置文件/文件夹
## 首先创建一些文件夹：
mkdir -p /root/es_kibana_7.17.27/es_config
mkdir -p /root/es_kibana_7.17.27/es_data
mkdir -p /root/es_kibana_7.17.27/es_plugins
mkdir -p /root/es_kibana_7.17.27/es_logs

## 然后复制配置文件/文件夹, 将容器内config下的所有文件复制到宿主机上es_config文件夹下
docker cp temp-es:/usr/share/elasticsearch/config/. /root/es_kibana_7.17.27/es_config
# 更改文件夹权限，为了后续可以读写， 1000:0 需要根据实际情况修改
chown -R 1000:0 /root/es_kibana_7.17.27
chmod -R 777 /root/es_kibana_7.17.27

# 关掉上面临时启动的容器
docker stop temp-es

# docker 启动 -v 挂载方式启动
docker run -d --name es01 -p 9200:9200 -p 9300:9300 \
  --net esnet \
  -e "discovery.type=single-node" \
  -e ES_JAVA_OPTS="-Xms512m -Xmx512m" \
  -v /root/es_kibana_7.17.27/es_config/:/usr/share/elasticsearch/config/ \
  -v /root/es_kibana_7.17.27/es_data/:/usr/share/elasticsearch/data \
  -v /root/es_kibana_7.17.27/es_plugins/:/usr/share/elasticsearch/plugins \
  -v /root/es_kibana_7.17.27/es_logs/:/usr/share/elasticsearch/logs \
  elasticsearch:7.17.27
```


2. volume 方式，将配置文件、数据文件、日志文件都挂载到宿主机上(由docker自动管理，不需要手动管理权限)
```bash
docker run -d --name es01 -p 9200:9200 -p 9300:9300 \
  --net esnet \
  -e "discovery.type=single-node" \
  -e ES_JAVA_OPTS="-Xms512m -Xmx512m" \
  -v es7.17.27_config:/usr/share/elasticsearch/config/ \
  -v es7.17.27_data:/usr/share/elasticsearch/data \
  -v es7.17.27_plugins:/usr/share/elasticsearch/plugins \
  -v es7.17.27_logs:/usr/share/elasticsearch/logs \
  elasticsearch:7.17.27
```

验证服务是否启动
```bash
curl "http://localhost:9200"
```



# kibana docker 启动（kibana的版本必须与es的版本严格一致）
```bash
mkdir -p /root/es_kibana_7.17.27/kibana_config

# docker 临时启动一个 kibana 容器，用于复制配置文件到宿主机上
docker run -d --rm --name kibana --net esnet -p 5601:5601 kibana:7.17.27
# 查看运行的 UID 与 GID 
docker exec -it kibana bash
cat /etc/passwd # 查看用户
# 查看运行的 UID 与 GID 
id  # 启动时的用户
# id ： uid=1000(kibana) gid=1000(kibana) groups=1000(kibana),0(root)
id 用户名  # 查看用户名对应的 UID 与 GID
# id kibana  # uid=1000(kibana) gid=1000(kibana) groups=1000(kibana),0(root)


# 将配置文件复制到宿主机上
docker cp kibana:/usr/share/kibana/config/. /root/es_kibana_7.17.27/kibana_config/
# 更改文件夹权限，为了kibana容器的用户后续可以读写， 1000:1000 需要根据实际情况修改
chown -R 1000:1000 /root/es_kibana_7.17.27/kibana_config
chmod -R 777 /root/es_kibana_7.17.27/kibana_config

# 关掉上面临时启动的容器
docker stop kibana
docker rm kibana

# docker 启动 -v 挂载方式启动, 将 kibanna 配置文件 挂载到宿主机上
docker run -d --name kibana --net esnet -p 5601:5601 -v /root/es_kibana_7.17.27/kibana_config/:/usr/share/kibana/config/ kibana:7.17.27

## vim 配置一下 /root/es_kibana_7.17.27/kibana_config/kibana.yml
## 修改以下内容：
server.host: "0.0.0.0"                        
server.shutdownTimeout: "5s"
elasticsearch.hosts: ["http://es01:9200"]     # 可以使用es01 是因为两个容器均属于自定义的esnet网络，所以可以直接使用es容器名通信，当然也可以使用宿主机的ip地址(公网私网ip均可)，先前容器启动时已经将容器的9200端口映射到了宿主机的9200端口
monitoring.ui.container.elasticsearch.enabled: true

## 重启kibana容器
docker restart kibana
```





# 使用 docker-compose.yml 安装
## docker-compose.yml 仅仅使用 volume 方式挂载
[从零开始搭建单节点 ELK](https://lihui.net/2024-08-24-install-and-config-elk.html)


### single node ES + kibana docker-compose启动
```yml
services:
  elasticsearch:
    image: elasticsearch:7.17.27
    ports:
      - "9200:9200"
      - "9300:9300"
    networks:
      - es_kibana
    environment:
      - "discovery.type=single-node"
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    volumes:
      - es_config:/usr/share/elasticsearch/config
      - es_data:/usr/share/elasticsearch/data
      - es_plugins:/usr/share/elasticsearch/plugins
      - es_logs:/usr/share/elasticsearch/logs
    depends_on:
      - kibana

  kibana:
    image: kibana:7.17.27
    ports:
      - "5601:5601"
    networks:
      - es_kibana
    volumes:
      - kibana_config:/usr/share/kibana/config
      - kibana_data:/usr/share/kibana/data

volumes:
  es_data:
    name: es_data7.17.27
  es_config:
    name: es_config7.17.27
  es_plugins:
    name: es_plugins7.17.27
  es_logs:
    name: es_logs7.17.27
  kibana_config:
    name: kibana_config7.17.27
  kibana_data:
    name: kibana_data7.17.27

networks:
  # 自动创建一个网络  es_kibana 
  es_kibana:
    name: es_kibana
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 192.187.0.0/24
          gateway: 192.187.0.1
```

```bash
# 创建目录
mkdir -p /root/es_kibana_7.17.27
# 启动
cd /root/es_kibana_7.17.27
# 创建上面的 docker-compose.yml 文件
vim docker-compose.yml
## 验证配置文件是否正确
docker-compose config
## 后台启动
docker-compose up -d
## 查看日志 
docker-compose logs -f

## 本地验证服务是否启动成功
curl http://localhost:9200
### 浏览器访问 http://公网ip:9200     http://公网ip:5601   



## 如果上述访问失败（上述docker-compose.yml 启动一般不会失败），
## 如果失败可能需要修改一些配置文件，修改一次后，后续启动由于都会使用volume挂载，所以无需再次修改
### 找到 详细的配置文件路径
docker network ls
docker volume ls
docker volume inspect es_config
docker volume inspect kibana_config
### 跳转到对应的目录后，按需修改配置文件
参考上文的kibana配置文件修改即可


## 重启
docker-compose down
docker-compose up -d
```




# IK分词器安装（解决中文分词问题，解压安装到上述挂在的plugins目录下即可）
- 注意: IK分词器的版本和kibana一样,需要和es的版本一致, 小版本号也要一致
- 注意: Docker 容器运行的ES安装插件的目录为 /usr/share/elasticsearch/plugins, 但如果使用了 -v 挂载方式启动，那么插件目录为挂载目录，例如：/root/elasticsearch/7.17.27/plugins 或 docker 管理的 volume 目录

[ik 分词 下载地址](https://github.com/infinilabs/analysis-pinyin/releases)

```bash
# 1. 将下载好的 elasticsearch-analysis-ik-7.17.27.zip 上传至服务器
## 或者使用wget下载
mkdir -p ik7.17.27        # ik7.17.27 为ik分词器自定义的目录，可以随意命名（最好是全英文）
cd ik7.17.27
wget https://release.infinilabs.com/analysis-ik/stable/elasticsearch-analysis-ik-7.17.27.zip

# 2. 解压 elasticsearch-analysis-ik-7.17.27.zip
# sudo apt install unzip
unzip elasticsearch-analysis-ik-7.17.27.zip 
rm -rf elasticsearch-analysis-ik-7.17.27.zip

## 更改ik分词器的用户组与权限
sudo chown -R 1000:0 ik7.17.27
sudo chmod -R 777 ik7.17.27  # 775 表示所有者有读写执行权限，组用户有读写权限，其他用户无写权限

# 3. 将整个文件夹 mv 到 容器elasticsearch挂载的plugins目录下, 例如：/var/lib/docker/volumes/es_plugins7.17.27/_data
cp ik7.17.27 /var/lib/docker/volumes/es_plugins7.17.27/_data
ll

# 4. 重启 docker-compose
docker-compose down
docker-compose up -d

```
ik 分词器可以自定义词典与sotp word 词典

```bash
# 进入到 ik 分词器目录，里面存在一个config目录，里面包含一个 IKAnalyzer.cfg.xml 文件
cd /var/lib/docker/volumes/es_plugins7.17.27/_data/ik7.17.27/config
vim IKAnalyzer.cfg.xml    # 可以按需进行一些修改

```






# docker 安装 mysql
[docker mysql 安装mysql csdn文章](https://blog.csdn.net/wangchange/article/details/137624224)

```bash
# 临时启动
docker run -d --rm -p 3306:3306 --name mysql_main \
  -v /etc/localtime:/etc/localtime:ro \
  -e LOWER_CASE_TABLE_NAMES=1 \
  -e MYSQL_ROOT_PASSWORD=123456 \
  mysql:8.0.41

# 查看容器内部用户的 UID 与 GID 
docker exec -it mysql_main bash
cat /etc/passwd # 查看用户
# 查看运行的 UID 与 GID 
id  # 启动时的用户
# id ： uid=0(root) gid=0(root) groups=0(root)
id 用户名  # 查看用户名对应的 UID 与 GID
# id mysql  uid=999(mysql) gid=999(mysql) groups=999(mysql)

## 停止并删除 mysql_main 容器
docker stop mysql_main



# 创建挂载目录
mkdir -p /root/mysql_main_volume/log
mkdir -p /root/mysql_main_volume/data
mkdir -p /root/mysql_main_volume/mysql
mkdir -p /root/mysql_main_volume/mysql/conf.d

chown -R 999:999 /root/mysql_main_volume
chmod -R 777 /root/mysql_main_volume




# 持久化启动
docker run --restart=always -d -p 3306:3306 --name mysql_main \
  -v /root/mysql_main_volume/log/:/var/log/mysql \
  -v /root/mysql_main_volume/data/:/var/lib/mysql \
  -v /root/mysql_main_volume/mysql/:/etc/mysql \
  -v /etc/localtime:/etc/localtime:ro \
  -e LOWER_CASE_TABLE_NAMES=1 \
  -e MYSQL_ROOT_PASSWORD=123456 \
  mysql:8.0.41
```


# docker-compose 启动
```yml
services:
  mysql_main:
    image: mysql:8.0.41
    ports:
      - "3306:3306"
    networks:
      - sqlnet
    environment:
      - MYSQL_ROOT_PASSWORD=123456
      - LOWER_CASE_TABLE_NAMES=1
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - mysql_log:/var/log/mysql
      - mysql_data:/var/lib/mysql
      - mysql_conf:/etc/mysql
    restart: always

volumes:
  mysql_log:
    name: mysql8.0.41_log
  mysql_data:
    name: mysql8.0.41_data
  mysql_conf:
    name: mysql8.0.41_conf

networks:
  # 自动创建一个网络  sqlnet 
  sqlnet:
    name: sqlnet
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 192.184.0.0/24
          gateway: 192.184.0.1
```





查看docker启动的 mysql 是否允许`用户root`远程访问，默认的情况下，`root用户允许远程访问`的

```bash
# 进入容器内部创建并授权用户
#进入容器内部
docker exec -it mysql_main /bin/bash
#登录mysql,不要输入密码，两次按两次回车键即可
mysql -u root -p
#查看数据库
show databases;
#切换到mysql库
use mysql;
# 查看 root 用户是否支持远程访问：
SELECT host, user FROM mysql.user;
+-----------+------------------+
| host      | user             |
+-----------+------------------+
| %         | root             | <-- 允许 root 从任何主机连接
| localhost | mysql.infoschema |
| localhost | mysql.session    |
| localhost | mysql.sys        |
| localhost | root             | <-- 仅允许 root 从本地连接
+-----------+------------------+
# 如果 root 用户不支持远程访问，可以运行以下 SQL 命令，将 root 用户的主机从 localhost 改为 %，允许任何主机通过网络连接到此用户：
  # 如果 root 用户还没有所有数据库的权限，可以运行以下命令确保授予权限：
  # 运行以下 SQL 命令，将 root 用户的主机从 localhost 改为 %，允许任何主机通过网络连接到此用户：
  UPDATE user SET host = '%' WHERE user = 'root';
  # 刷新权限
  FLUSH PRIVILEGES;
  # 如果 root 用户还没有所有数据库的权限，可以运行以下命令确保授予权限：
  GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' WITH GRANT OPTION;

#使用exit命令退出mysql
exit;
#使用exit命令退出mysql容器
exit;
```


创建 my.cnf 文件，并修改配置文件，开启 binlog 等功能
**bind-address = 0.0.0.0 允许mysqld服务远程访问, 这里配置与上文不同，上面是`用户root允许远程访问`，这里修改的是`mysqld服务允许远程访问`，一般情况docker 启动的mysql服务默认是允许远程访问的**

```bash
## 查看mysql容器 读取配置文件的位置
docker exec -it mysql_main /bin/bash
mysql --help | grep my.cnf
# /etc/my.cnf /etc/mysql/my.cnf /usr/etc/my.cnf ~/.my.cnf  , 后续我们可以在宿主机挂载的目录：/root/mysql_main_volume/mysql 目录下创建my.cnf文件，并修改配置文件
exit


# 进入到mysql容器挂载的目录，创建my.cnf文件
cd /root/mysql_main_volume/mysql
vim my.cnf

"""
[client]
default-character-set=utf8mb4

[mysql]
default-character-set=utf8mb4

[mysqld]
# 设置东八区时区
default-time_zone = '+8:00'

# 设置密码验证规则，保持兼容性
authentication_policy=mysql_native_password

# 限制导入和导出的数据目录
# 留空表示不限制导出/导入的数据目录
secure_file_priv=

# 初始化连接时设置字符集
init_connect='SET collation_connection = utf8mb4_general_ci'
init_connect='SET NAMES utf8mb4'

# 配置字符集
character-set-server=utf8mb4
collation-server=utf8mb4_general_ci
skip-character-set-client-handshake
skip-name-resolve


# 开启 binlog
## 数据库的id(唯一id)
server_id=1
## 启动binlog，指定binlog日志文件名称为binlog
log_bin=mysql-bin
# binlog 日志格式
binlog_format=ROW

# 启动binlog的数据库，需要按需修改
binlog_do_db=testdb

# 完整记录行信息（8.x的新特性）
binlog_row_image=FULL
# 设置日志保留天数    
expire_logs_days=30


# 配置数据库表名小写（跨平台建议打开）
# lower_case_table_names=1

# 远程访问相关配置
# 设置监听所有网络接口，允许远程连接
bind-address = 0.0.0.0
# # 关闭主机名解析（提高连接速度）
# skip-name-resolve
# # 调整最大连接数（可根据需求修改）
# max_connections = 600
"""

# 更改一下权限
chown -R 999:999 /root/mysql_main_volume
chmod -R 777 /root/mysql_main_volume
cd /root/mysql_main_volume/mysql/
chmod -R 664 my.cnf  # 可读可写 可读可写 可读

# 重启docker容器
docker restart mysql_main
```



测试 binlog 是否开启成功
```bash
# 进入容器内部
docker exec -it mysql_main /bin/bash
# 登录mysql,不要输入密码，两次按两次回车键即可
mysql -u root -p
# 查看binlog是否开启
SHOW VARIABLES LIKE 'log_bin';
# 通过查看 binlog 文件
SHOW VARIABLES LIKE 'log_bin_basename';
# 检查 binlog 格式
SHOW VARIABLES LIKE 'binlog_format';
# 测试生成 binlog 数据
## 1. 在 MySQL 中创建一个测试表并插入数据，验证 binlog 是否记录了这些修改。
CREATE DATABASE testdb;
USE testdb;
CREATE TABLE test_table (id INT PRIMARY KEY, name VARCHAR(50));
INSERT INTO test_table VALUES (1, 'Test');

## 2. 如果 binlog 已启用，执行后可以用 mysqlbinlog 工具解析二进制日志以检查是否记录了这次操作。
mysqlbinlog /root/mysql_main_volume/mysql/mysql-bin.000001
mysqlbinlog --database=your_database_name /root/mysql_main_volume/mysql/mysql-bin.000001

```





测试可否实现远程连接
```bash
# 方法一：宿主机上安装mysql客户端（注意：这里仅仅安装客户端），通过宿主机ip连接mysql
# 安装mysql客户端
sudo apt-get update
sudo apt-get install mysql-client

# 测试连接
mysql -h 110.42.XXX.XXX -u root -p
# 输入密码即可测试连接

sudo apt-get remove mysql-client
```

```bash
# 方法二：启动一个新的docker容器，测试远程连接
# 再起一个docker容器，测试远程连接
docker run -d --rm -p 3305:3306 --name mysql_test \
  -v /etc/localtime:/etc/localtime:ro \
  -e LOWER_CASE_TABLE_NAMES=1 \
  -e MYSQL_ROOT_PASSWORD=123456 \
  mysql:8.0.41

# 进入容器内部
docker exec -it mysql_test /bin/bash

# 使用宿主机公网ip连接mysql
mysql -h <宿主机公网ip> -u root -p
#如：
mysql -h 110.42.XXX.XXX -u root -p
# 输入密码即可测试连接

# 停止并删除测试容器
docker stop mysql_test
```













# ES 基础命令

```plaintext


# 查看es中的索引
GET /_cat/indices
GET /_cat/indices?v


# 创建一个自定义的索引products
PUT /products

PUT /order 
{
  "settings": {
    "number_of_shards": 1, 
    "number_of_replicas": 0
  }
}


# 删除索引
DELETE /products
DELETE /order

# 创建索引products + mapping {id, title, price, created_at, description }
PUT /products
{
  "settings": {
    "number_of_shards": 1,
    "number_of_replicas": 0
  },
  "mappings": {
    "properties": {
      "id": {
        "type": "integer"
      },
      "title": {
        "type": "keyword"
      },
      "price": {
        "type": "double"
      },
      "created_at": {
        "type": "date"
      },
      "description": {
        "type": "text"
      }
    }
  }
}


# 查看某个索引的具体信息
GET /products
## 查看映射信息 _mapping
GET /products/_mapping
## 查看 _segments
GET /products/_segments


## ES 索引没有修改的功能，只能删除后新建



# 索引内部加入文档的操作

## 添加文档
### /1 表示手动指定文档的id为 1，不指定es会使用uuid自动生成文档id

POST /products/_doc/1
{
  "id": 1,
  "title": "小浣熊",
  "price": 0.5,
  "created_at": "2022-12-03",
  "description": "小浣熊真的非常的好吃"
}


## 添加文档操作，自动生成 uuid 为标识的id： 例如： "_id" : "nDJNEpUBo7OshN5I7tzz" 
POST /products/_doc
{
  "title": "日本豆",
  "price": 1.5,
  "created_at": "2022-12-04",
  "description": "日本豆很不错"
}

## 文档查询 
### 基于doc id 查询文档
GET /products/_doc/1
GET /products/_doc/04pRHJUBAaUzS2_A5GAk


## 文档删除
### 基于doc id 删除文档
DELETE /products/_doc/04pRHJUBAaUzS2_A5GAk

## 更新文档
### 基于doc id 更新文档
#### 需要注意的是：/put 会删除原始文档，再从新添加，因此更新需要传入全部的字段
PUT /products/_doc/1
{
  "id": 1,
  "title": "小浣熊熊",
  "description": "小浣熊熊真的非常的好吃"
}

### 基于指定的字段更新文档：在源文档的基础之上更新
POST /products/_doc/1/_update
{
  "doc": {
    "id": 1,
    "title": "小浣熊",
    "price": 1.0,
    "created_at": "2022-12-05",
    "description": "小浣熊真的非常的好吃"
  }
}



# 文档的批量操作 _bulk  添加 两个文档
### 注意：下面插入的文档数据需要保证在一行内部，不能缩进
POST /products/_doc/_bulk
{"index":{"_id":2}}
  {"id":2,"title":"日本豆","price":1.5,"created_at":"2022-12-04","description":"日本豆很不错"}
{"index":{"_id":3}}
  {"id":3,"title":"鱼豆腐","price":4.8,"created_at":"2022-12-04","description":"鱼豆腐真好吃，真好吃"}


GET /products/_doc/2
GET /products/_doc/3


POST /products/_doc/_bulk
{"index":{"_id":17}}
  {"id":17,"title":"milk","price":20.5,"created_at":"2022-12-04","description":"A mAn who drinks Milk."}



# 文档的批量操作 _bulk   添加 更新 删除
POST /products/_doc/_bulk
{"index":{"_id":4}}
  {"id":4,"title":"甜不辣","price":6.7,"created_at":"2022-12-04","description":"甜不辣真好吃"}
{"update": {"_id":3}}
  {"doc":{"title":"小鱼豆腐"}}
{"delete":{"_id":2}}


GET /products/_doc/1




# ES 中的高级查询 Query DSL 语法

## 查询所有 match_all 关键词
### 1. 第一种：/GET /索引名/_doc/_search {json 结构体}

GET /products/_doc/_search
{
  "query":{
    "match_all":{}
  }
}


### 2. 第二种： /GET /索引名/_search {json 结构体}
GET /products/_search
{
  "query": {
    "match_all": {}
  }
}


## 关键词查询（term 关键词）
### GET /索引名/_search {json 结构体}

GET /products/_mapping

### term 基于关键词查询 
### keywork integer double date 类型ES不会分词
### text 类型存储中es会对其进行分词，默认情况下会使用标准分词，标准分词中中文是按字分词的
### 总结：
# 1. 在Es中除了text类型的数据会进行分词，其余类型均不分词
# 2. 在Es中默认使用标准分词器，中文单字分词，英文单词分词
GET /products/_search
{
  "query": {
    "term": {
      "title": {
        "value": "小浣熊"
      }
    }
  }
}


## 范围查询（range关键词）
## gte 大于等于   lte 小于等于     gt 大于     le 小于
GET /products/_search
{
  "query": {
    "range": {
      "price": {
        "gte": 0,
        "lte": 5
      }
    }
  }
}



## 前缀查询[prefix关键词]
GET /products/_search
{
  "query": {
    "prefix": {
      "title": {
        "value": "小浣"
      }
    }
  }
}


## 通配符查询（wildcard 查询）
## ? 一个随意的
## * 多个随意的
GET /products/_search
{
  "query": {
    "wildcard": {
      "title": {
        "value": "小*"
      }
    }
  }
}


## 多id查询（ids）, 查询一组符合条件的id
GET /products/_search
{
  "query": {
    "ids": {
      "values": [1,3,4]
    }
  }
}


## 模糊查询（fuzzy），可以允许查询关键词略微出入
### fuzzy 能允许的最大的错误次数为2
# 1. 当搜索的关键词长度<=2 时， 官方不允许模糊查询
# 2. 当搜索的关键词长度 3-5， 官方允许出现一次错误
# 3. 当搜索的关键词长度>5，官方允许出现最多2次错误
GET /products/_search
{
  "query": {
    "fuzzy": {
      "title": "小浣狗熊"
    }
  }
}
GET /products/_search
{
  "query": {
    "fuzzy": {
      "title": "小浣猫"
    }
  }
}


## 布尔查询
### bool 关键词如下：
# 1. must：相当于&& 同时成立
# 2. should： 相当于 || 成立一个就行
# 3. must_not：相当于! 不能满足任何一个
# must should 或 must_not 内部 可以使用各种查询关键词 

GET /products/_search
{
  "query": {
    "bool": {
      "must": [
        {
          "ids": {
            "values": [1,4,15]
          }
        },
        {
          "term": {
            "title": {
              "value": "小浣熊"
            }
          }
        }
      ]
    }
  }
}


GET /products/_search
{
  "query": {
    "bool": {
      "should": [
        {
          "ids": {
            "values": [1,4,15]
          }
        },
        {
          "term": {
            "title": {
              "value": "小浣熊"
            }
          }
        }
      ]
    }
  }
}


GET /products/_search
{
  "query": {
    "bool": {
      "must_not": [
        {
          "ids": {
            "values": [1,4,15]
          }
        },
        {
          "term": {
            "title": {
              "value": "小浣熊"
            }
          }
        }
      ]
    }
  }
}

## 多字段查询（multi_match）
# multi_match 会自动根据字段的类似是否使用分词器进行分词
# 1. 如果字段是 text 类型(es会分词)， query会先分词后搜索
# 2. 如果字段非text类型(es不分词)，query会直接进行搜索

GET /products/_search
{
  "query": {
    "multi_match": {
      "query": "豆腐",
      "fields": ["description","title"]
    }
  }
}


GET /products/_search
{
  "query": {
    "multi_match": {
      "query": "小浣熊",
      "fields": ["title"]
    }
  }
}

GET /products/_search
{
  "query": {
    "multi_match": {
      "query": "浣鱼",
      "fields": ["title","description"]
    }
  }
}

#### 测试大小写英文query 是否会自动转小写查询
#### 使用 man mAn miLk 查询测试
GET /products/_search
{
  "query": {
    "match_all": {}
  }
}

GET /products/_search
{
  "query": {
    "multi_match": {
      "query": "miLk",
      "fields": ["description"]
    }
  }
}


## 字段分词查询（query_string）
### 与上面 multi_match 类似，query_string 也会根据字段的类型开启是否分词
GET /products/_search
{
  "query": {
    "query_string": {
      "default_field": "title",
      "query": "浣熊"
    }
  }
}

GET /products/_search
{
  "query": {
    "query_string": {
      "default_field": "title",
      "query": "小浣熊"
    }
  }
}

GET /products/_search
{
  "query": {
    "query_string": {
      "default_field": "description",
      "query": "浣熊鱼"
    }
  }
}


# Query DSL 其他的特性
## 高亮查询
GET /products/_search
{
  "query": {
    "query_string": {
      "default_field": "description",
      "query": "浣熊鱼"
    }
  },
  "highlight": {
    "fields": {
      "*":{}
    }
  }
}

### 自定义高亮的标签 pre_tags  post_tags
### require_field_match 可以控制是否仅搜索字段验证
GET /products/_search
{
  "query": {
    "query_string": {
      "default_field": "description",
      "query": "浣熊鱼"
    }
  },
  "highlight": {
    "pre_tags": ["<span style='color:red;'>"], 
    "post_tags": ["</span>"], 
    "require_field_match": "false", 
    "fields": {
      "*":{}
    }
  }
}

### 返回指定条数（size）
GET /products/_search
{
  "query": {
    "match_all": {}
  }
}

GET /products/_search
{
  "query": {
    "match_all": {}
  },
  "size": 2
}

### 分页查询（from）
# from 关键字，表示从指定的索引位置开始，from 1 表示从索引位置为1（即第二条）
GET /products/_search
{
  "query": {
    "match_all": {}
  }
}

GET /products/_search
{
  "query": {
    "match_all": {}
  },
  "size": 2,
  "from":0
}

GET /products/_search
{
  "query": {
    "match_all": {}
  },
  "size": 2,
  "from":2
}

### 指定字段进行排序
# 降序 desc  正序 asc
GET /products/_search
{
  "query": {
    "match_all": {}
  }
}

GET /products/_search
{
  "query": {
    "match_all": {}
  },
  "size": 10,
  "from":0,
  "sort": [
    {
      "price": {
        "order": "asc"
      }
    }
  ]
}

### 查询返回指定字段（_source 关键词）
GET /products/_search
{
  "query": {
    "match_all": {}
  },
  "size": 10,
  "from":0,
  "sort": [
    {
      "price": {
        "order": "asc"
      }
    }
  ],
  "_source": ["id", "title","description"]
}


# 索引的原理
## 倒排索引：value -> id
## 正向索引：id  ->   记录
DELETE /products

GET _cat/indices

PUT /products
{
  "mappings": {
    "properties": {
      "description": {
        "type": "text"
      },
      "price":{
        "type": "double"
      },
      "title":{
        "type": "keyword"
      }
    }
  }
}

PUT /products/_doc/_bulk
{"index":{"_id":1}}
  {"title":"蓝月亮洗衣液","price":19.9, "description":"蓝月亮洗衣液很高效"}
{"index":{"_id":2}}
  {"title":"iphone13","price":19.9, "description":"很不错的手机"}
{"index":{"_id":3}}
  {"title":"小浣熊干脆面","price":1.5, "description":"小浣熊很好吃"}


GET /products/_search
{
  "query": {
    "match_all": {}
  }
}

GET /products/_search
{
  "query": {
    "term": {
      "price": {
        "value": 19.9
      }
    }
  }
}

GET /products/_search
{
  "query": {
    "term": {
      "description": {
        "value": "蓝"
      }
    }
  }
}

GET /products/_search
{
  "query": {
    "term": {
      "description": {
        "value": "很"
      }
    }
  }
}




# 分析器（分词器）
# Character Filter（0个或多个） ->  Tokenizer ->  Token Filter（0个或多个） 大小写转换，停用词

## 默认分词器：Standard Analyzer - 英文按单词切分， 并小写处理


### standard 分词器测试
POST /_analyze
{
  "analyzer": "standard",
  "text": "我是中国人 我是中华人民共和国的一个普通群众，this is good MAN"
}


### simple 分词器测试
POST /_analyze
{
  "analyzer": "simple",
  "text": "我是中国人 我是中华人民共和国的一个普通群众，this is good MAN"
}


### whitespace 分词器测试
POST /_analyze
{
  "analyzer": "whitespace",
  "text": "我是中国人 我是中华人民共和国的一个普通群众，this is good MAN"
}


### keyword 分词器测试
POST /_analyze
{
  "analyzer": "keyword",
  "text": "我是中国人 我是中华人民共和国的一个普通群众，this is good MAN"
}



# 创建索引时使用分词器
PUT /test
{
  "settings": {},
  "mappings": {
    "properties": {
      "title":{
        "type": "text",
        "analyzer": "standard"
      }
    }
  }
}

GET _cat/indices?v

PUT /test/_doc/1
{
  "title": "我是小黑，this is good mAn"
}

GET /test/_search
{
  "query": {
    "match_all": {}
  }
}

GET /test/_search
{
  "query": {
    "term": {
      "title": {
        "value": "小"
      }
    }
  }
}

# 测试 小写英文与大写英文的查询测试
GET /test/_search
{
  "query": {
    "term": {
      "title": {
        "value": "man"
      }
    }
  }
}
GET /test/_search
{
  "query": {
    "term": {
      "title": {
        "value": "MAN"
      }
    }
  }
}



### IK 分词器测试 （IK 插件需要安装）
# 两种模式
# 1. ik_smart: 会做最粗粒度的分词
# 2. ik_max_word: 会做最细粒度的拆分

POST /_analyze
{
  "analyzer": "ik_smart",
  "text":"中华人民共和国国歌"
}

POST /_analyze
{
  "analyzer": "ik_max_word",
  "text":"中华人民共和国国歌"
}

DELETE /test

PUT /test
{
  "settings": {},
  "mappings": {
    "properties": {
      "title":{
        "type": "text",
        "analyzer": "ik_max_word"
      }
    }
  }
}

PUT /test/_doc/1
{
  "title":"今天是中国成立多少年，应该放中华人民共和国国歌"
}

GET /test/_search
{
  "query": {
    "match_all": {}
  }
}

GET /test/_search
{
  "query": {
    "term": {
      "title": {
        "value": "中国"
      }
    }
  }
}



## 过滤查询（filter query）


```